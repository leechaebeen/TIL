[openjdk-jdk11/HashMap](https://github.com/AdoptOpenJDK/openjdk-jdk11/blob/master/src/java.base/share/classes/java/util/HashMap.java) 을 읽고 해석한 내용입니다.


## **HashMap 이란?**

Hash table 은 Map 인터페이스를 기반으로 하는 구현체이다. 이 구현은 모든 Map 연산을 제공하고 null 값과 null 키를 허용한다. `HashMap` 클래스는  `HashTable` 클래스와 거의 동일하지만 동기화 되지 않고 null 을 허용한다는 차이가 있다. `HashMap`은 맵의 순서에 대해 어떤 보장도 하지 않고 특히 시간이 지나면 순서가 일정하게 유지될거라고 보장하지 않는다. 

기본 연산 `get` 과 `put` 에 대해 상수 시간 성능 `O(1)` 을 제공한다. 단, 해시 함수가 요소들을 버킷에 고르게 분산시킨다는 전제가 있다. Iteration 은 인스턴스의 용량(버킷 수) 와 크기(키-값 매핑 수) 에 비례하는 시간이 필요하다. 따라서 반복 성능이 중요한 경우 초기 용량을 너무 높게 설정하거나 부하 계수(load factor) 를 너무 낮게 설정하지 않는 것이 중요하다. 

## **초기 용량과 부하 계수**

`HashMap` 인스턴스에는 성능에 영향을 미치는 두 가지 매개변수가 있다. 초기 용량과 부하 계수이다. 용량은 해시 테이블의 버킷 수를 의미하고 초기 용량은 해시 테이블이 생성될 때의 용량을 말한다.

부하 계수는 해시테이블이 얼마나 채워질 수 있는지를 나타내는 값으로, 이 값에 따라 용량이 자동으로 증가하기 전까지 해시 테이블이 얼마나 차게 둘 수 있는지를 결정한다. **해시 테이블에 있는 항목 수가 부하 계수와 현재 용량의 곱을 초과하게 되면 해시 테이블이 재해시 된다. 데이터 구조가 재구성되어 해시 테이블의 버킷 수가 대략 2배로 증가한다.**   
`💡Q. 왜 2배로 증가하는가? 아래의 비트 연산에서 설명`

일반적으로, 기본 부하 계수(0.75) 는 시간과 공간 비용 사이에서 좋은 균형을 제공한다. 부하 계수를 높이면 공간 오버헤드는 줄어들지만 조회 비용이 증가한다. ( `HashMap` 클래스의  `get` 과 `put` 을 포함한  대부분의 연산에서) 맵에 예상되는 항목 수와 부하 계수를 고려하여 초기 용량을 설정하면, 재해시(rehash) 작업의 횟수를 최소화할 수 있다. 초기 용량이 최대 항목 수를 부하 계수로 나눈 값보다 크다면 재해시 작업이 발생하지 않는다.

많은 매핑을 `HashMap` 인스턴스에 저장해야 하는 경우, 충분히 큰 용량으로 생성하면 자동 재해시를  통해 테이블을 크기를 늘리는 것보다 더 효율적으로 매핑을 저장할 수 있다. 또한 동일한 `hashCode()` 값을 가진 많은 키를 사용하는 것은 해시 테이블의 성능을 저하시킨다. 이런 영향을 완화하기 위해 키가 `Comparable` 을 구현하는 경우, 키 간의 비교 순서를 사용해서 충돌을 해결할 수 있다.

## **동기화 되지 않는다.**

`HashMap` 은 동기화되지 않는다는 점에 유의해야 한다. 멀티스레드가 `HashMap` 에 동시에 접근하고 그중 적어도 하나의 스레드가 맵을 구조적으로 수정하는 경우, 반드시 외부에서 동기화되어야 한다. (구조적 수정은 하나 이상의 매핑을 추가하거나 삭제하는 모든 작업을 의미하고 단순히 이미 포함된  키에 연결된 값을 변경하는 것을 말하는 것은 아니다) 일반적으로 맵을 자연스럽게 캡슐화하는 객체에 대해 동기화를 수행하여 이를 해결한다. 

만약 동기화를 위한 객체가 존재하지 않는다면 맵은 `Collections.synchronizedMap` 메서드를 사용해서 감싸져야 한다. 맵에 대해 동기화 되지 않은 접근을 방지하기 위해 생성 시에 수행하는 것이 가장 좋다.

```java
   Map m = Collections.synchronizedMap(new HashMap(...));
```

## **Iterator Fail-Fast**

이 클래스의 컬렉션 조회 메서드가 반환하는 `Iterator` 는 fail-fast 동작을 한다.  `Iterator` 가 생성된 후에 반복자의 자체 메서드 `remove()` 를 통한 경우를 제외하고 맵이 구조적으로 수정되면  `Iterator` 는 `ConcurrentModificationException` 를 던진다. 따라서 동시 수정이 발생한 경우  `Iterator` 는 나중에 예기치 못한 동작이 발생하는 것을 방지하고 신속하고 명확하게 실패하도록 설계되었다. 

 `Iterator` 의 fail-fast 동작은 보장되지 않는다는 점에 유의해야 한다. Fast-fail  `Iterator`  는 최선의 노력을해서 `ConcurrentModificationException` 을 던지려고하지만,  일반적으로 동기화 되지 않은 상태에서 동시 수정이 발생하는 경우 이를 완벽하게 보장하는 것은 불가능하다. 그러므로 이 예외에 의존해서 프로그램의 정확성을 유지하려고 하는건 잘못되었다. `Iterator`  의 fail-fast 동작은 버그를 감지하는 용도로만 사용해야 한다.

# 코드 살펴보기

### **인터페이스 `Cloneable` 과 `Serializable` 을 구현하는 이유**

```java
public class HashMap<K,V> extends AbstractMap<K,V>
    implements Map<K,V>, Cloneable, Serializable {
    ...
    }
```

1. `Cloneable`  : 인터페이스를 구현하지 않으면, `CloneNotSupportedException` 이 발생해서  `Object` 클래스에서 제공되는 `clone()` 메서드를 사용할 수 없다. `clone()` 메서드는  얕은 복사를 수행한다. 맵 자체의 객체는 새로 생기지만, 키와 값으로 저장된 객체들은 새로 생성되지 않고 참조만 복사한다. 

2. `Serializable`  : 인터페이스를 구현하지 않으면 `NotSerializableException` 이 발생해서 직렬화 할 수 없다.  직렬화를 통해 `HashMap` 인스턴스를 파일로 저장하거나 네트워크로 전송할 수 있게 된다. 직렬화된 `HashMap` 객체는 나중에 다시 역직렬화(deserialization)를 통해 복원할 수 있어, 데이터를 장기 저장하거나 다른 프로그램 간에 공유할 수 있다.

### **serialVersionUID 의 용도**

```java
private static final long serialVersionUID = 362498820763181265L;
```

직렬화된 객체의 버전을 식별하기 위한 고유 ID 이다.   serialVersionUID 를 명시적으로 정의하면, 클래스의 변경이 있더라도 같은 ID를 유지할 수 있어, 버전 불일치로 인한 역직렬화 오류를 방지할 수 있다.

### **`TreeNode` 로 이루어진 버킷이란?**

`HashMap` 은 일반적으로 버킷화된 해시 테이블로 동작하지만, 버킷이 너무 커질 경우 `TreeNodes` 의 버킷으로 변환되며, 각 노드는 `java.util.TreeMap` 구조와 유사하게 구성된다. 이렇게 각 노드가 트리 구조로 변환된 버킷이 `TreeNode` 로 이루어진 버킷이다.

대부분의 메서드는 일반 버킷을 사용하려 하지만 필요한 경우 `instanceof` 를 통해 노드가 `TreeNode` 인지 확인해서 `TreeNode` 메서드로 전달된다. `TreeNode` 로 이루어진 버킷도 다른 버킷처럼 탐색되고 사용할 수 있지만  추가적으로 과밀되었을 때 더 빠른 조회를 지원한다. 하지만 일반적으로 대부분의 버킷은 과밀화되지 않으므로, `TreeNode` 로 이루어진 버킷인지 확인하는 작업을 매번 수행하지 않는다.

### **`TreeNode`  로 이루어진 버킷의 존재 이유와 사용하는 이유**

`TreeNode`  로 이루어진 버킷은 주로 `hashCode`에 따라 정렬되지만, 동일한 해시 값을 가지는 경우에 각 요소가 동일한 `Comparble` 인터페이스를 구현할 때는 (class C implements Comparable<C>)  `compareTo` 메서드를 사용하여 정렬한다. (이를 확인하기 위해 제네릭 타입을 리플렉션으로 보수적으로 검사한다. `comparableClassFor` 메서드 참고) 

 `TreeNode` 로 이루어진 버킷을 사용하면 복잡해지지만 최악의 경우에도 O(log n)의 연산을 제공하기 때문에 가치가 있다. 이는 `hashCode()`가 고르게 분포되지 않는 경우나 많은 키가 동일한 해시 값을 가지는 경우에도 성능 저하를 완화하며, 이러한 키가 `Comparable`을 구현하고 있는 경우 성능이 더 개선된다. (이 두 조건이 적용되지 않으면, 시간과 공간에서 약 두 배 정도의 낭비가 있을 수 있다. 하지만 이는 이미 성능이 매우 느린 부적절한 프로그래밍 관행에서 발생하는 문제이기 때문에 큰 영향은 없다.)

### **`TreeNode` 변환 기준과 발생 확률**

`TreeNode` 는 일반 노드의 약 두 배 크기이므로, 버킷에 충분한 수의 노드가 포함되어 있을 때만 사용된다. (TREEIFY_THRESHOLD 참고)  삭제나 크기 조정으로 노드가 너무 적어지면 다시 일반 버킷으로 변환된다. 사용자가 제공한 해시 코드가 잘 분포되어 있는 경우 트리 버킷은 거의 사용되지 않는다. 이상적으로는 임의의 해시 코드 아래에서 노드의 분포가 포아송 분포를 따르며 기본 리사이징 임계치가 0.75 일 때 평균 약 0.5의 파라미터를 가진다. 다만 리사이징의 구체젝인 정도로 인해 큰 분산이 발생할 수 있습니다. 분산을 무시하고 기대되는 버킷 크기 k (같은 버킷에 담긴 노드의 수)의 발생 활률은 다음과 같다. (exp(-0.5) * pow(0.5, k) / factorial(k))

| 버킷 크기 (k) | 발생 확률 |
| --- | --- |
| 0 | 0.60653066 |
| 1 | 0.30326533 |
| 2 | 0.07581633 |
| 3 | 0.01263606 |
| 4 | 0.00157952 |
| 5 | 0.00015795 |
| 6 | 0.00001316 |
| 7 | 0.00000094 |
| 8 | 0.00000006 |
| 그 이상 | 천만 번에 1보다 적음 |

따라서, 이상적인 상황에서는 대부분의 버킷이 매우 작은 크기(0~1개 노드)일 것이며, 더 큰 버킷이 생길 확률은 매우 낮다.

`TreeNode` 로 이루어진 버킷의 루트 노드는 일반적으로 첫번째 노드이지만 특정 상황에서는 루트가 다른 위치에 있을 수 있다. 현재로서는 주로 `Iterator.remove` 메서드를 사용할 때 이러한 상황이 발생한다. 이 경우 `parent` 링크를 따라가면서 `TreeNode.root()` 메서드를 통해 루트 노드를 복원할 수 있다.

### **최적화를 위한 HashMap 내부 메서드의 설계**

모든 관련 내부 메서드는 해시 코드를 인수로 받아들인다. 따라서 동일한 해시 코드를 반복해서 계산하지 않고 인수로 받은 해시 코드를 계속 사용할 수 있다. 해시 코드는 해시맵의 키를 기반으로 하는 작업을 수행할 때 필요하다.

또한 대부분의 내부 메서드는 "tab" 인수를 받아들이는데, 이는 해시 테이블을 의미한다. 일반적으로 현재 테이블을 의미하지만, 리사이징이나 변환 중일 때는 새로운 테이블 또는 기존 테이블일 수 있다. 이를 통해 현재 테이블을 직접 수정하지 않고도 변환 중에 작업을 처리할 수 있다. 

### 구조 변경할 때 기존 노드 순서를 유지한다

버킷 목록을 트리 구조로 변환(treeify)하거나 분할(split)하거나 리스트 구조로 되돌릴(untreeify) 때, 상대적인 접근/탐색 순서 (즉, `Node.next` 필드)를 동일하게 유지해서 데이터의 지역성(locality)을 더 잘 보존하고,  `iterator.remove`를 호출하는 분할 및 탐색 처리 작업을  단순화한다. 

 요소가 추가될 때 `comparator` 를 사용하면 리밸런싱 작업에서 전체 순서를 유지하기 위해 클래스 및 `identityHashCode`를 순위 결정자로 사용한다.

### HashMap 의 구조 전환과 LinkedHashMap

일반 구조와 트리 구조 간의 전환은 `LinkedHashMap` 서브클래스의 존재로 인해 복잡해진다. `LinkedHashMap`은 `HashMap`을 상속한 클래스이며, 순서를 유지하기 위해 이중 연결 리스트를 사용하여 각 요소가 삽입된 순서를 보존한다.
`LinkedHashMap`의 특성을 유지하면서 `HashMap`의 트리 모드를 구현하려면, 삽입, 삭제, 접근 시 추가적인 작업이 필요하다. 이를 위해 훅 메서드를 사용하여 `LinkedHashMap`이 `HashMap`의 구조적 변화에 독립적으로 대응할 수 있게 한다.
훅 메서드는 특정 작업(예: 요소 삽입이나 삭제)이 발생할 때 자동으로 호출되어 `LinkedHashMap`이 `HashMap`의 구조 변화에 맞게 업데이트된다.
동시 프로그래밍과 유사한 SSA 기반 코딩 스타일을 사용하면 복잡한 포인터 연산 중 발생할 수 있는 참조 오류(aliased error)를 방지하는 데 도움이 된다. SSA(Static Single Assignment) 기반 코딩 스타일은 각 변수가 단일 할당만을 갖도록 코드가 작성되는 방식이다. 이를 통해 코드가 복잡해져도 변수의 값이 혼동되지 않게 되어 참조 오류(같은 변수를 잘못 참조하는 오류)가 줄어든다.

## 상수의 의미

```java
 	  /**
     * The default initial capacity - MUST be a power of two.
     *  HashMap 의 기본 초기 용량 설정값 
     *  해시 충돌을 줄이고 계산을 최적화하기위해 2의 거듭제곱이어야 한다.
     */
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

    /**
     * The maximum capacity, used if a higher value is implicitly specified
     * by either of the constructors with arguments.
     * MUST be a power of two <= 1<<30. // 1,073,741,824
     * HashMap 의 최대 용량 설정값  
     */
    static final int MAXIMUM_CAPACITY = 1 << 30;

    /**
     * The load factor used when none specified in constructor.
     * HashMap 의 기본 부하 계수 (해시 테이블이 얼마나 차게 둘지 정하는 값)
     * 메모리 사용량과 성능 간의 균형을 고려한 최적의 값이 0.75
     */
    static final float DEFAULT_LOAD_FACTOR = 0.75f;

    /**
     * The bin count threshold for using a tree rather than list for a
     * bin.  Bins are converted to trees when adding an element to a
     * bin with at least this many nodes. The value must be greater
     * than 2 and should be at least 8 to mesh with assumptions in
     * tree removal about conversion back to plain bins upon
     * shrinkage.
     * 버킷을 트리로 변환하는 기준값
     * 충돌이 적은 경우에는 트리구조로 변환할 필요 없기 때문에 2보다 커야 한다.
     * 8 이상이어야 트리에서 리스트로 전환하는 과정에서 예상한 성능과 구조적 효율성을 유지할 수 있다.
     */
    static final int TREEIFY_THRESHOLD = 8;

    /**
     * The bin count threshold for untreeifying a (split) bin during a
     * resize operation. Should be less than TREEIFY_THRESHOLD, and at
     * most 6 to mesh with shrinkage detection under removal.
     * 버킷을 리스트로 변환하는 기준값, TREEIFY_THRESHOLD 값보다 작아야 한다. 
     * 버킷에 있는 노드 수가 기준 값 이하로 줄어들면 트리 구조에서 리스트 구조로 변환한다.
     * 최대값이 6인 이유는 트리에서 리스트로 전환하는 조건과 일관성을 유지하기 위해서이다.
     */
    static final int UNTREEIFY_THRESHOLD = 6;

    /**
     * The smallest table capacity for which bins may be treeified.
     * (Otherwise the table is resized if too many nodes in a bin.)
     * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts
     * between resizing and treeification thresholds.
     * 버킷을 트리 구조로 변환할 수 있는 최소 테이블 용량 값 
	   * 리사이즈와 트리 변환의 기준을 명확하게 구분하기 위해 TREEIFY_THRESHOLD 의 4배 이상이어야 한다.
	   
	   * HashMap 의 전체 용량이 64 이상일 때만 버킷을 트리 구조로 변경할 수 있다. 
	   * HashMap 의 용량이 64보다 작다면 트리로 변환하는 대신 테이블을 리사이즈 한다.
	   * 작은 테이블에서 트리로 변환하는 것보다는, 테이블 용량을 늘리는 것이 해시 충돌을 줄이는 데 더 효과적이기 때문이다. 
     */
    static final int MIN_TREEIFY_CAPACITY = 64;
```

## 비트 연산

Java `HashMap`은 해시 충돌을 줄이기 위해 데이터가 일정 수준 이상으로 채워지면 크기를 두 배로 늘린다. 이를 리사이징(resizing)이라고 하는데, 이때 기본값인 16의 크기인 경우 리사이징이 발생하면 2의 거듭제곱인 32로 증가한다. 이 과정을 예시를 통해 살펴보자.

### 예시: 두 개의 키 `A`와 `B`가 같은 해시 코드를 가진 경우

두 개의 키 `A`와 `B`가 해시 코드 `00101100` (즉, 44)을 가진다고 가정해보자. 초기 `HashMap`의 크기가 16일 때와, 리사이징되어 크기가 32가 되었을 때를 비교해 보겠다.

### 1. 초기 `HashMap` 크기 16인 경우 (2^4)

- **길이 - 1**: 크기가 16이므로, `length - 1`은 15(`00001111`).
- **키 `X`의 해시 코드와 인덱스 계산**:
    - 해시 코드: `00010001` (17)
    - 인덱스: `00010001 & 00001111` = `00000001` (1)
- **키 `Y`의 해시 코드와 인덱스 계산**:
    - 해시 코드: `00110001` (49)
    - 인덱스: `00110001 & 00001111` = `00000001` (1)

따라서, `X`와 `Y`는 인덱스 1에 위치하게 된다. 이때 충돌이 발생하여 두 항목이 같은 버킷에 저장된다.

### 2. `HashMap` 크기를 32로 리사이징한 경우 (2^5)

- **길이 - 1**: 크기가 32이므로, `length - 1`은 31(`00011111`).
- **키 `X`의 인덱스 계산**:
    - 해시 코드: `00010001` (17)
    - 인덱스: `00010001 & 00011111` = `00010001` (17)
- **키 `Y`의 인덱스 계산**:
    - 해시 코드: `00110001` (49)
    - 인덱스: `00110001 & 00011111` = `00110001` (49)

리사이징 후에도 `X`와 `Y`가 같은 해시 코드를 가져서 여전히 같은 인덱스에 위치할 수 있다. 그러나 리사이징으로 `HashMap`의 전체 버킷 수가 늘어났기 때문에 다른 해시 코드들을 가진 키들이 새로운 위치에 분산될 수 있다. **즉, 전체적으로 충돌이 줄어들어 `HashMap`의 효율성이 향상된다.**

### 왜 `HashMap`은 크기를 두 배로 증가시키는가?

1. **해시 분포 최적화**: 크기를 두 배로 늘리면 전체 인덱스가 2의 거듭제곱이 되어 `&` 연산을 통해 효율적으로 해시 값을 배열 인덱스로 변환할 수 있다. (1추가, 기존 인덱스에 + oldCap 하면 돼서)
2. **충돌 감소**: 두 배로 늘리면 버킷이 더 많이 생기므로, 기존에 충돌이 발생했던 키들이 더 넓게 분포되어 충돌이 줄어든다. `HashMap`의 부하율(Load Factor)에 도달하면 크기를 늘려 더 많은 데이터를 저장하고 검색 성능을 유지한다.

이와 같은 방식으로, `HashMap`은 효율적인 검색 성능을 유지하기 위해 크기를 두 배로 증가시키며, 항상 2의 거듭제곱으로 유지하여 빠른 인덱스 계산을 보장한다.
